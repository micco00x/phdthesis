\chapter{Nonlinear model predictive control based on real-time iteration}
Model Predictive Control (MPC) is a technique used to control complex 
constrained systems that, in the fast few years, has seen an increased
interest in both acadamia and industry. It works by solving on-line a
finite horizon Optimal Control Problem (OCP), which considers a prediction 
model of the system, its constraints, the constraints on the
control inputs, and a cost function to be minimized (which reflects the
desired behavior of the system itself).
At each timestep, the controller receives a new measurement of the state of 
the system, and it uses it to solve the OCP, obtaining an optimal control action,
which is applied to the system for a small time interval
\cite{Mayne2014MPCAutomatica}. These steps are repeated at each new measurement 
of the state, which acts as feedback of the MPC itself.

Among the categories of MPC, Linear MPC (LMPC) is the most common one.
Indeed, because in LMPC the prediction model and the constraints are linear,
and the function is quadratic, the associated OCP can be efficienly solved
via a Quadratic Programming (QP) problem \cite{Gros2020Fromlineartononlinear}. 
Nevertheless, most of the systems that we are interested in controlling are 
nonlinear. That is particularly true in robotics, where the systems exhibit
both a nonlinear model, and nonlinear constraints. While, in principle, it is 
possible to apply a LMPC to a nonlinear system by linearizing it around a 
reference trajectory, it is often preferred to treat nonlinear dynamics and 
constraints explicitely.

Nonlinear MPC (NMPC) \cite{Diehl2009EfficientNumericalMethodsNMPC} allows to use 
nonlinear models, constraints, and cost functions, at the price of higher 
computational cost with respect to LMPC. While this makes it more complex to 
deploy such kind of techniques on real platforms, recent progress in efficient
algorithms \cite{Diehl2005RTI}, and availability of powerful processing power,
is making the adoption of NMPC more and more common.

This chapter gives a brief overview on Nonlinear MPC, focusing in particular on
the real-time iteration scheme \cite{Gros2020Fromlineartononlinear}. The 
algorithms presented here will be used in Chapter \ref{ch:nmpc-swmr} to develop 
a Nonlinear MPC for the control of the motion of a steerable wheeled mobile 
robot.

\section{Optimal control problem and MPC formulation}
Consider a robotic system whose equations of motion are described by the 
ordinary differential equation
\begin{equation}
    \label{eq:generic-prediction-model}
    \dot{\bm{q}}(t) = \bm{f}(\bm{q}(t), \bm{u}(t)),
\end{equation}
with $\bm{q}\in\mathbb{R}^n$ state of the system, $\bm{u}\in\mathbb{R}^m$
control inputs, and $\bm{q}(t_0)=\bm{q}_0$ initial state of the system itself.
Moreover, assume that the system is subject to constraints of the 
kind
\begin{equation}
    \label{eq:generic-constraints}
    \bm{h}(\bm{q}(t), \bm{u}(t)) \le \bm{0},
\end{equation}
which collect linear constraints (e.g., hardware limitations due to actuators),
and nonlinear constraints (e.g., collision avoidance constraints due to 
complex environments) on the state and the control inputs of the system\footnote{
We choose not to separate the notation on linear and nonlinear constraints to 
make the description of the chapter simpler. Bear in mind, however, that 
modern implementations take it into account in order to improve the
performance of the software \cite{Verschueren2021acados}.
}.

At each time instant $t_k$, given the estimate $\hat{\bm{q}}_k$ of the system,
the NMPC solves an OCP over a finite horizon $[t_k, t_k + T]$, taking into account the 
prediction model \eqref{eq:generic-prediction-model} and the constraints 
\eqref{eq:generic-constraints}. The OCP can be formulated as
\begin{equation}
    \label{eq:OCP}
    \begin{aligned}
        \min_{\bm{u}(\cdot)} \;\;
            & \; \Phi(\bm{q}(t_k + T)) + \int_{t_k}^{t_k + T} \mathcal{L}(\bm{q}, \bm{u}) dt \\
            \text{s.t. } & \dot{\bm{q}}(t) = \bm{f}(\bm{q}(t), \bm{u}(t)) \\
                         %& \bm{q}^- \le \bm{q}(t) \le \bm{q}^+ \\
                         %& \bm{u}^- \le \bm{u}(t) \le \bm{u}^+ \\
                         & \bm{h}(\bm{q}(t), \bm{u}(t)) \le \bm{0} \\
                         & \bm{q}(t_k) = \hat{\bm{q}}_k,
    \end{aligned}
\end{equation}
with $\Phi(\bm{q}(t_k + T))$ terminal cost, and $\mathcal{L}(\bm{q}, \bm{u})$
stage cost. The solution of the OCP gives an optimal control input $\bm{u}_k^*(t)$,
which is defined over the prediction horizon $[t_k, t_k + T]$.

Given $\bm{u}_k^*(t)$, the NMPC extracts the control input
$\bm{u}_k^{\mathrm{NMPC}}$, corresponding to the subinterval $[t_k, t_k + \delta]$,
with $\delta$ sampling time of the NMPC. The control action $\bm{u}_k^{\mathrm{NMPC}}$
is then applied to the system over the same interval $[t_k, t_k + \delta]$.
This steps, which describes the NMPC algorithm, summarized in Algorithm 
\ref{alg:NMPC}, are repeated each time a new estimate of the state is available.

\begin{algorithm}
	\small
	\caption{NMPC algorithm}
	\label{alg:NMPC}
	%\KwIn{inputs}
    $k \leftarrow 0$\;
    \While{\textit{true}}{
        $t_k \leftarrow k\delta$\;
        $\hat{\bm{q}}_k \leftarrow$ receive the estimated state of the system at time $t_k$\;
        $\bm{u}_k^*(t) \leftarrow$ solve the OCP \eqref{eq:OCP} over $t \in [t_k, t_k + T]$\;
        $\bm{u}_k^{\mathrm{NMPC}} \leftarrow$ extract from $\bm{u}_k^*(t)$ the optimal control input corresponding to time interval $[t_k, t_k + \delta]$\;
        apply $\bm{u}_k^{\mathrm{NMPC}}$ to the system over the time interval $[t_k, t_k + \delta]$\;
        $k \leftarrow k + 1$\;
    }
\end{algorithm}

\section{Numerical methods for the OCP solution}
The solution of the OCP \eqref{eq:OCP} is fundamental for the NMPC algorithm.
Indeed, the method chosen determines the performance and the behavior of the 
NMPC itself.

In literature, there exists three classes for the numerical solution of the OCP.

The first one is based on \textit{dynamic programming} and
\textit{Hamilton-Jacobi-Bellman}
equation \cite{Bertsekas2005DynamicProgrammingandOptimalControl}, and requires the solution of a 
partial differential equation. These methods, however, suffer from the curse of 
dimensionality and they are suitable only to system whose state dimension
is small.

The second class are the \textit{indirect methods}, which are based on
Pontryagin's minimum principle \cite{Liberzon2012CalculusofVariations}, and
consist in solving a multi-point boundary value problem for an ordinary 
differential equation.

The third class are \textit{direct methods}, and consists in transcribing 
the OCP (which is infinite-dimesional and continuous-time) into a Nonlinear
Programming Problem (NLP). In literature, there exists three transcription 
approaches (\textit{direct collocation}, \textit{single shooting} and 
\textit{multiple shooting}), whose difference depends on the way in which the
state and the conrol inputs are discretized.

Direct collocation discretizes both state and
control inputs using 
piecewise continuous polynomials, resulting in a large and sparse NLP
\cite{Hargraves1986Collocation}.
Single shooting discretizes only the control inputs, resulting in a smaller NLP
(whose decision variables are the control inputs themselves), which is however
sensitive to nonlinearities and instabilities of the system
\cite{Zanon2017DirectOptimalControlandMPC}. Multiple shooting discretizes 
both the state and the control inputs, obtaining a large and sparse NLP (which 
is smaller then the one obtained through collocation), guaranteeing continuity
of the solution by adding appropriate constraints on the shooting nodes
\cite{Bock1984MultipleShooting}.

In the following, we give a brief overview on multiple shooting, which will be 
used in Chapter \ref{ch:nmpc-swmr} for the transcription of the OCP associated 
to the trajectory tracking problem of a steerable wheeled mobile robot.

\subsection{Multiple shooting}
In order to discretize the OCP \eqref{eq:OCP} using the multiple shooting method,
the prediction horizon $[t_k, t_k + T]$ is partitioned into N subintervals
\begin{equation}
    \label{eq:subinterval-prediction-horizon}
    t_k < t_{k+1} < \dots < t_{k+N} = t_k + T,
\end{equation}
where, typically, each subinterval has the same duration, and it is equal to 
the sampling time of the NMPC, i.e. $t_{k+i+1}=t_{k+i}+\delta$.
The control trajectory $\bm{u}(t)$ is discretized assuming it is piecewise
constant over each subinterval, i.e.,
\begin{equation*}
    \bm{u}(t) = \bm{u}_{k|i}, \ \forall t \in [t_{k+i}, t_{k+i+1}],
\end{equation*}
with $\bm{u}_{k|i}\in\mathbb{R}^m$.

The prediction model \eqref{eq:generic-prediction-model} is discretized over each 
subinterval by using a numerical integration method
\cite{Butcher2016NumericalMethodsforODE} (typically the fourth order Runge-Kutta
method). Denoting by $\bm{F}(\cdot)$ the discrete-time dynamics of the 
system \eqref{eq:generic-prediction-model}, the prediction model is discretized
in the following way:
\begin{equation*}
    \bm{q}_{i+1|k} = \bm{F}(\bm{q}_{i|k}, \bm{u}_{i|k}), \ \forall i \in \mathbb{I}_{0}^{N-1}
\end{equation*}
with $\mathbb{I}_a^b=\{a,\, \dots,\, b\}\subset\mathbb{N}$ subset
of natural numbers containing all naturals from $a$ to $b$.
The cost function of the OCP and the constraints
\eqref{eq:generic-constraints} are evaluated at the corresponding nodes of the 
subintervals \eqref{eq:subinterval-prediction-horizon}.

The infinite-dimensional OCP \eqref{eq:OCP} is hence transformed into the 
following finite-dimensional NLP:
\begin{equation}
    \label{eq:transcribed-OCP}
    \begin{aligned}
        \min_{\bm{Q}_k, \bm{U}_k} \;\;
            & \; \Phi(\bm{q}_{N|k}) + \sum_{i=0}^{N-1} \mathcal{L}(\bm{q}_{i|k}, \bm{u}_{i|k}) \\
            \text{s.t. } & \bm{q}_{i+1|k} = \bm{F}(\bm{q}_{i|k}, \bm{u}_{i|k}), \ \forall i \in \mathbb{I}_{0}^{N-1} \\
                         %& \bm{q}^- \le \bm{q}_{i|k} \le \bm{q}^+, \ \forall i \in \mathbb{I}_{0}^{N} \\
                         %& \bm{u}^- \le \bm{u}_{i|k} \le \bm{u}^+, \ \forall i \in \mathbb{I}_{0}^{N-1} \\
                         & \bm{h}(\bm{q}_{i|k}, \bm{u}_{i|k}) \le \bm{0}, \ \forall i \in \mathbb{I}_{0}^{N-1} \\
                         & \bm{q}_{0|k} = \bm{q}_k,
    \end{aligned}
\end{equation}
with
\begin{align*}
\bm{Q}_k &= (\bm{q}_{0|k}^\top, \bm{q}_{1|k}^\top, \dots, \bm{q}_{N|k}^\top)^\top \\
\bm{U}_k &= (\bm{u}_{0|k}^\top, \bm{u}_{1|k}^\top, \dots, \bm{u}_{N-1|k}^\top)^\top
\end{align*}
collecting the decision variables of the NLP.

Most of the optimization solvers use methods such as Interior-Point method and 
Sequential Quadratic Programming (SQP) \cite{Nocedal2006NumericalOptimization}
to solve the NLP \eqref{eq:transcribed-OCP}. In this manuscript, we are 
going to solve the NMPC using the real-time iteration scheme
\cite{Gros2020Fromlineartononlinear}, which is based on SQP.

\subsection{Sequential Quadratic Programming}
Todo.

\section{The real-time iteration}
\begin{algorithm}
	\small
	\caption{RTI for NMPC at $t_k$}
	\label{alg:RTI}
    \underline{Preparation phase}\;
	\KwIn{previous NMPC solution $\bm{Q}_{k-1}, \bm{U}_{k-1}$}
    shift $\bm{Q}_{k-1}, \bm{U}_{k-1}$\;
    evaluate sensitivities\;
    prepare QP omitting $\hat{\bm{q}}_k$\;
    \Return{QP}\;
    \underline{Feedback phase}\;
    \KwIn{$\hat{\bm{q}}_k$, QP}
    compute what's missing in QP\;
    full Newton step\;
    \Return{NMPC solution $\bm{Q}_k, \bm{U}_k$}\;
\end{algorithm}

\section{Conclusions}
Todo.